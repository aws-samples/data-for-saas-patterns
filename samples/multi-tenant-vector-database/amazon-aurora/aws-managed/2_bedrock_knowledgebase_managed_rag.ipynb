{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 - Bedrock Knowledge Base Managed RAG with Aurora Vector Store\n",
    "\n",
    "Prerequisites before you run these scripts : \n",
    "1. Deploy an Aurora PostgreSQL Cluster with RDS Data API enabled. You can make use of the CDK stack [here](../cdk/README.md). \n",
    "2. Create the vector db schema, table & index using [aws-managed/1_build_vector_db_on_aurora.sql](1_build_vector_db_on_aurora.sql)\n",
    "3. Note the cluster ARN from the Aurora PostgreSQL Cluster\n",
    "4. Note the secret Key ARN for the Aurora cluster database username/password.\n",
    "5. Create a Secrets Manager secret key for the database user bedrock_user (used for RLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the boto3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U boto3==1.34.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and clients bedrock_agent, bedrock-agent-runtime, bedrock-runtime,S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "bedrock_agent_client = boto3.client(\n",
    "    service_name=\"bedrock-agent\", region_name=region_name\n",
    ")\n",
    "bedrock_agent_runtime = boto3.client(\n",
    "    service_name=\"bedrock-agent-runtime\", region_name=region_name\n",
    ")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", region_name=region_name)\n",
    "\n",
    "s3_client = boto3.client(service_name=\"s3\", region_name=region_name)\n",
    "\n",
    "iam = boto3.client('iam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update ARNs & variables from Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the ARN for Aurora Cluster and Secrets for the user bedrock_user\n",
    "rds_aurora_cluster_arn = \"<update aurora cluster arn>\"\n",
    "bedrock_user_secret_arn = \"<update bedrock_user secret ARN>\"\n",
    "database_name = \"postgres\"\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "bucket_name = f\"multi-tenant-home-survey-reports-{account_id}\"\n",
    "embedding_model_id = \"amazon.titan-embed-text-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function upload document to S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to upload a document to S3\n",
    "def upload_file_to_s3(file_name, bucket, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    try:\n",
    "        s3_client.upload_file(file_name, bucket, object_name)\n",
    "        print(f\"File '{file_name}' uploaded to '{bucket}/{object_name}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file '{file_name}' to '{bucket}/{object_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the Bedrock Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the Bedrock Knowledge Base\n",
    "def create_knowledge_base(\n",
    "    name, description, roleArn, embeddingModelArn, rdsConfiguration\n",
    "):\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        roleArn=roleArn,\n",
    "        knowledgeBaseConfiguration={\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            },\n",
    "        },\n",
    "        storageConfiguration={\"type\": \"RDS\", \"rdsConfiguration\": rdsConfiguration},\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Function to create the datasource in Bedrock Knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the Datasource in Bedrock Knowledge Base\n",
    "def create_datasource_in_knowledge_base(\n",
    "    name, description, knowledgeBaseId, s3Configuration\n",
    "):\n",
    "    create_datasource_response = bedrock_agent_client.create_data_source(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        knowledgeBaseId=knowledgeBaseId,\n",
    "        dataSourceConfiguration={\"type\": \"S3\", \"s3Configuration\": s3Configuration},\n",
    "    )\n",
    "    return create_datasource_response[\"dataSource\"]\n",
    "\n",
    "\n",
    "def wait_for_ingestion(start_job_response):\n",
    "    job = start_job_response[\"ingestionJob\"]\n",
    "    while job[\"status\"] != \"COMPLETE\":\n",
    "        get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            dataSourceId=ds_id,\n",
    "            ingestionJobId=job[\"ingestionJobId\"],\n",
    "        )\n",
    "        job = get_job_response[\"ingestionJob\"]\n",
    "    print(job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Invoke Anthrophic Claude LLM on Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to invoke the LLM\n",
    "def generate_message(bedrock_runtime, model_id, system_prompt, messages, max_tokens):\n",
    "\n",
    "    body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": messages\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body\n",
    "\n",
    "def invoke_llm_with_rag(messages):\n",
    "    model_id = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "    response = generate_message (bedrock_runtime, model_id, \"\", messages, 300)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve vector data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve chunks from vector store through KB\n",
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    response = bedrock_agent_runtime.retrieve(\n",
    "        retrievalQuery={\"text\": query},\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\"numberOfResults\": numberOfResults}\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve vector data chunks with filter enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve chunks from vector store through KB\n",
    "def retrieve_with_filters(query, kbId, tenantId, numberOfResults=5):\n",
    "    tenant_filter = {\"equals\": {\"key\": \"tenantId\", \"value\": tenantId}}\n",
    "    response = bedrock_agent_runtime.retrieve(\n",
    "        retrievalQuery={\"text\": query},\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": numberOfResults,\n",
    "                \"filter\": tenant_filter,\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the IAM role and necessary policies for the Bedrock Knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject these variable values into the policy templates and generate policies using sed. \n",
    "%env region_name = $region_name\n",
    "%env account_id = $account_id\n",
    "%env bucket_name = $bucket_name\n",
    "%env rds_aurora_cluster_arn = $rds_aurora_cluster_arn\n",
    "%env bedrock_user_secret_arn = $bedrock_user_secret_arn\n",
    "%env embedding_model_id = $embedding_model_id\n",
    "\n",
    "!sed -e \"s/\\#account_id\\#/$account_id/\" -e \"s/\\#bucket_name\\#/$bucket_name/\" policy-templates/bedrock_data_source_permissions_policy.json > bedrock_data_source_permissions_policy.json\n",
    "!sed -e \"s/\\#embedding_model_id\\#/$embedding_model_id/\" -e \"s/\\#region_name\\#/$region_name/\" policy-templates/bedrock_model_permissions_policy.json > bedrock_model_permissions_policy.json\n",
    "!sed -e \"s/\\#rds_aurora_cluster_arn\\#/$rds_aurora_cluster_arn/\" policy-templates/bedrock_aurora_cluster_permissions_policy.json > bedrock_aurora_cluster_permissions_policy.json\n",
    "!sed -e \"s/\\#bedrock_user_secret_arn\\#/$bedrock_user_secret_arn/\" policy-templates/bedrock_secrets_permissions_policy.json > bedrock_secrets_permissions_policy.json\n",
    "!sed -e \"s/\\#account_id\\#/$account_id/\" -e \"s/\\#region_name\\#/$region_name/\" policy-templates/bedrock_trust_relationship_policy.json > bedrock_trust_relationship_policy.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the role and attach policies\n",
    "\n",
    "# bedrock-kb-service-role\n",
    "!aws iam create-role \\\n",
    "    --role-name bedrock_kb_service_role \\\n",
    "    --assume-role-policy-document file://bedrock_trust_relationship_policy.json\n",
    "\n",
    "# bedrock_model_permissions_policy\n",
    "!aws iam create-policy \\\n",
    "    --policy-name bedrock_model_permissions_policy \\\n",
    "    --policy-document file://bedrock_model_permissions_policy.json\n",
    "\n",
    "!aws iam attach-role-policy \\\n",
    "    --role-name bedrock_kb_service_role \\\n",
    "    --policy-arn \"arn:aws:iam::$account_id:policy/bedrock_model_permissions_policy\"\n",
    "\n",
    "# bedrock_aurora_cluster_permissions_policy\n",
    "!aws iam create-policy \\\n",
    "    --policy-name bedrock_aurora_cluster_permissions_policy \\\n",
    "    --policy-document file://bedrock_aurora_cluster_permissions_policy.json\n",
    "\n",
    "!aws iam attach-role-policy \\\n",
    "    --role-name bedrock_kb_service_role \\\n",
    "    --policy-arn \"arn:aws:iam::$account_id:policy/bedrock_aurora_cluster_permissions_policy\"\n",
    "\n",
    "# bedrock_secrets_permission_policy\n",
    "!aws iam create-policy \\\n",
    "    --policy-name bedrock_secrets_permissions_policy \\\n",
    "    --policy-document file://bedrock_secrets_permissions_policy.json\n",
    "\n",
    "!aws iam attach-role-policy \\\n",
    "    --role-name bedrock_kb_service_role \\\n",
    "    --policy-arn \"arn:aws:iam::$account_id:policy/bedrock_secrets_permissions_policy\"\n",
    "\n",
    "# bedrock_data_source_permissions_policy\n",
    "!aws iam create-policy \\\n",
    "    --policy-name bedrock_data_source_permissions_policy \\\n",
    "    --policy-document file://bedrock_data_source_permissions_policy.json\n",
    "\n",
    "!aws iam attach-role-policy \\\n",
    "    --role-name bedrock_kb_service_role \\\n",
    "    --policy-arn \"arn:aws:iam::$account_id:policy/bedrock_data_source_permissions_policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the generated policy json files.\n",
    "!rm *.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Create the Bedrock Knowledge base\n",
    "The first step is to create the Bedrock Knowledge base.\n",
    "\n",
    "\n",
    "NOTE : Before your run this cell, ensure that you have gather the configurations from the Aurora PostgreSQL database and update the variables rds_aurora_cluster_arn and bedrock_user_secret_arn in the previous cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Create the Bedrock Knowledge Base\n",
    "\n",
    "rdsConfiguration = {\n",
    "    \"credentialsSecretArn\": str(bedrock_user_secret_arn),\n",
    "    \"databaseName\": str(database_name),\n",
    "    \"fieldMapping\": {\n",
    "        \"metadataField\": \"metadata\",\n",
    "        \"primaryKeyField\": \"id\",\n",
    "        \"textField\": \"chunks\",\n",
    "        \"vectorField\": \"embedding\",\n",
    "    },\n",
    "    \"resourceArn\": str(rds_aurora_cluster_arn),\n",
    "    \"tableName\": \"aws_managed.kb\",\n",
    "}\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\"maxTokens\": 512, \"overlapPercentage\": 20},\n",
    "}\n",
    "\n",
    "embeddingModelArn = (\n",
    "    f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    ")\n",
    "name = f\"home-survey-reports-knowledge-base\"\n",
    "description = \"Home Survey Reports - multi tenant knowledge base.\"\n",
    "roleArn = f\"arn:aws:iam::{account_id}:role/bedrock_kb_service_role\"\n",
    "\n",
    "kb = create_knowledge_base(\n",
    "    name, description, roleArn, embeddingModelArn, rdsConfiguration\n",
    ")\n",
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "\n",
    "time.sleep(20)\n",
    "print(f\"Knowledge Base created with ID: {kb_id}\")\n",
    "\n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId=kb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create a datasource in the Knowledge base\n",
    "Next let us create the datasource ( S3 bucket) and add it into the Knowledge base configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Create a datasource in the knowledge base\n",
    "s3_client.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket_name}\",\n",
    "}\n",
    "ds = create_datasource_in_knowledge_base(name, description, kb_id, s3Configuration)\n",
    "print(ds)\n",
    "ds_id = ds[\"dataSourceId\"]\n",
    "print(f\"Datasource created with ID: {ds_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Add Tenant1 document into the datasource \n",
    "Let us add a document for the Tenant1 into the datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Add Tenant1 document into the datasource (S3 bucket)\n",
    "upload_file_to_s3(\n",
    "    \"../multi_tenant_survey_reports/Home_Survey_Tenant1.pdf\", bucket_name, object_name=\"multi_tenant_survey_reports/Home_Survey_Tenant1.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Ingest the document from the datasource into the vector store.\n",
    "The newly added document from the datasource needs to be ingested into the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : Ingest data from the datasource into the vector store\n",
    "\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id, dataSourceId=ds_id\n",
    ")\n",
    "wait_for_ingestion(start_job_response)\n",
    "\n",
    "print(f\"Datasource ingestion completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Retrieve the vector data chunks that are similar to the user question.\n",
    "Now we can retrieve the vector data chunks from the Tenant1 document based on a user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 : Retrieve\n",
    "question = \"What is the condition of the roof in my survey report ? \"\n",
    "response = retrieve(question, kb_id)\n",
    "\n",
    "for i in response['retrievalResults']:\n",
    "    print(f\"source_document={i['location']['s3Location']['uri']}\")\n",
    "    print(f\"data_chunk={i['content']['text']}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "\n",
    "print(f\"Step5 - Retrieval of vector data completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Augment the prompt with the data chunks retrieved from the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Augment the prompt\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts\n",
    "\n",
    "contexts = get_contexts(response['retrievalResults'])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context\n",
    "Question: {question}\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 : Generate the response from the LLM\n",
    "Now we can finally generate the response from the LLM using the augmented prompt as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 : Generate the response from the LLM\n",
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(contexts, question)}]}]\n",
    "llm_response = invoke_llm_with_rag(messages)\n",
    "print(llm_response['content'][0]['text'])\n",
    "print(f\"Step7 - Generated response from LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Add more tenants and their documents\n",
    "\n",
    "Let us upload documents for a few more tenants : Tenant2, Tenant3, Tenant4, Tenant5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 : Add Tenant2, Tenant3, Tenant4 documents into the datasource (S3 bucket)\n",
    "upload_file_to_s3(\"../multi_tenant_survey_reports/Home_Survey_Tenant2.pdf\", bucket_name, object_name=\"multi_tenant_survey_reports/Home_Survey_Tenant2.pdf\")\n",
    "upload_file_to_s3(\"../multi_tenant_survey_reports/Home_Survey_Tenant3.pdf\", bucket_name, object_name=\"multi_tenant_survey_reports/Home_Survey_Tenant3.pdf\")\n",
    "upload_file_to_s3(\"../multi_tenant_survey_reports/Home_Survey_Tenant4.pdf\", bucket_name, object_name=\"multi_tenant_survey_reports/Home_Survey_Tenant4.pdf\")\n",
    "upload_file_to_s3(\"../multi_tenant_survey_reports/Home_Survey_Tenant5.pdf\", bucket_name, object_name=\"multi_tenant_survey_reports/Home_Survey_Tenant5.pdf\")\n",
    "\n",
    "print(f\"Step8- Uploaded more tenants documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Ingest the new tenant documents into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9 : Ingest new documents from the datasource into the vector database\n",
    "\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id, dataSourceId=ds_id\n",
    ")\n",
    "wait_for_ingestion(start_job_response)\n",
    "\n",
    "print(f\"Step9 - Ingestion of new documents completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10 : Retrieve the vector data related to Tenant3.\n",
    "Now we can attempt to retrieve vector data based on a question from Tenant3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10 : Retrieve the vector data related to the question of Tenant 1\n",
    "question = \"What is the condition of the roof in my survey report for Tenant3? \"\n",
    "response = retrieve(question, kb_id)\n",
    "\n",
    "print(f\"Step10 - Retrieving vector data for Tenant 1 - complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Review the results retrieved. \n",
    "The response will include data chunks from multiple tenant data. So the question is how do we enforce tenant isolation so that when we retrieve data from the vector database, we are able to limit it to a specific tenants data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11 : Review the results and validate the response. You will observe that the response includes chunks from other tenants as well.\n",
    "\n",
    "for i in response['retrievalResults']:\n",
    "    print(f\"source_document={i['location']['s3Location']['uri']}\")\n",
    "    print(f\"data_chunk={i['content']['text']}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "print(f\"Step11 - Review the results and validate the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Add metadata tagging to each tenant document. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12 : Add metadata tagging to each tenants document\n",
    "upload_file_to_s3(\n",
    "    \"../metadata_tags/Home_Survey_Tenant1.pdf.metadata.json\",\n",
    "    bucket_name,\n",
    "    \"multi_tenant_survey_reports/Home_Survey_Tenant1.pdf.metadata.json\",\n",
    ")\n",
    "\n",
    "upload_file_to_s3(\n",
    "    \"../metadata_tags/Home_Survey_Tenant2.pdf.metadata.json\",\n",
    "    bucket_name,\n",
    "    \"multi_tenant_survey_reports/Home_Survey_Tenant2.pdf.metadata.json\",\n",
    ")\n",
    "\n",
    "upload_file_to_s3(\n",
    "    \"../metadata_tags/Home_Survey_Tenant3.pdf.metadata.json\",\n",
    "    bucket_name,\n",
    "    \"multi_tenant_survey_reports/Home_Survey_Tenant3.pdf.metadata.json\",\n",
    ")\n",
    "\n",
    "upload_file_to_s3(\n",
    "    \"../metadata_tags/Home_Survey_Tenant4.pdf.metadata.json\",\n",
    "    bucket_name,\n",
    "    \"multi_tenant_survey_reports/Home_Survey_Tenant4.pdf.metadata.json\",\n",
    ")\n",
    "\n",
    "upload_file_to_s3(\n",
    "    \"../metadata_tags/Home_Survey_Tenant5.pdf.metadata.json\",\n",
    "    bucket_name,\n",
    "    \"multi_tenant_survey_reports/Home_Survey_Tenant5.pdf.metadata.json\",\n",
    ")\n",
    "\n",
    "print(f\"Step12 - Metadata tags for each document added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13 : Ingest the metadata tags into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13 : Ingest tags datasource into the vector database\n",
    "\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id, dataSourceId=ds_id\n",
    ")\n",
    "wait_for_ingestion(start_job_response)\n",
    "\n",
    "print(f\"Step13 - Ingestion completed for new metadata documents \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Retrieve the vector data with tenant filtering enabled.\n",
    "Amazon Bedrock Knowledge Base supports filtering using metadata tags. In the previous step we tagged each document with the tenant-id. During retrieval we can pass a filter configuration using the desired tenant-id to enforce the tenant specific data chunks are only retrieved from the underlying vector database of the knowledge base.  \n",
    "\n",
    "Review the response to validate that the data chunks retrieved are from the specific tenants document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 : Retrieve with filter enabled for tenantid=3\n",
    "question = \"What is the condition of the roof in my survey report  ? \"\n",
    "response = retrieve_with_filters(question, kb_id, 3)\n",
    "\n",
    "for i in response['retrievalResults']:\n",
    "    print(i['location']['s3Location']['uri'])\n",
    "    print(f\"data_chunk={i['content']['text']}\")\n",
    "    print(f\"tenantid={round(i['metadata']['tenantid'])}\")\n",
    "    print(\"------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
