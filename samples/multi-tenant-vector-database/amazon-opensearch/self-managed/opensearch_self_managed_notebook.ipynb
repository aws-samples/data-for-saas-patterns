{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-managed vector store using OpenSearch provisioned domain\n",
    "\n",
    "This notebook demonstrates the self-managed approach to build a vector store using OpenSearch features like remote model with a connector to Amazon Bedrock, ingestion pipeline, create an index using the pipeline, and implement multi-tenancy using attributes.\n",
    "\n",
    "Prerequisites before you run the cells in this notebook : \n",
    "1. Deploy an Amazon OpenSearch Domain. (If you are at an AWS event, these are pre-provisioned in your account)\n",
    "2. Note the vpc domain name of the OpenSearch cluster. You will need when accessing from within the VPC. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install boto3 & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U boto3==1.34.84\n",
    "%pip install -U opensearch-py requests_aws4auth\n",
    "%pip install pypdf\n",
    "%pip install langchain==0.2.7\n",
    "%pip install langchain-community==0.2.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SSH Tunnel to EC2 Bastion Host\n",
    "- If you are running this notebook from outside the VPC where the OpenSearch cluster is deployed then you can SSH tunnel to it using an EC2 bastion host\n",
    "- You may need to obtain the key-pair file contents from the parameter store of Systems Manager if you have provisioned the resources using the CloudFormation template.\n",
    "- Copy the contents from the parameter store and create key-pair.pem. \n",
    "- You need to add read permissions to the file using the \"chmod +400 key-pair.pem\" command on a terminal \n",
    "- Run the following command from a terminal after updating the key-pair.pem file, bastion host ip and the vpc domain name of the OpenSearch cluster. \n",
    "```bash\n",
    "ssh -i ~/.ssh/your-key.pem ec2-user@your-ec2-instance-public-ip -N -L 9200:vpc-domain-name.region.es.amazonaws.com:443\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the AWSSigV4Auth\n",
    "\n",
    "- If running this notebook from outside of the VPC, then update host = \"localhost\" after enabling the SSH tunnel to the EC2 bastion host. \n",
    "- If running this notebook from within VPC (VS Code Server provisioned by Workshop Studio), then update host = \"vpc-domain-name.region.es.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "host = \"localhost\"  # Update to vpc-domain-name when running from within the VPC\n",
    "\n",
    "host = host.replace(\"https://\", \"\")\n",
    "service = 'es'\n",
    "region = os.environ.get('AWS_REGION', 'us-west-2')\n",
    "session_name = \"opensearch-admin-session\"\n",
    "\n",
    "# 1. Create a AWSSigV4Auth from the assumed OpenSearch Admin Role \n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "admin_role_arn = f\"arn:aws:iam::{account_id}:role/opensearch-admin-role\"\n",
    "assumed_role = boto3.client('sts').assume_role(RoleArn=admin_role_arn,RoleSessionName=session_name)\n",
    "credentials = assumed_role['Credentials']\n",
    "master_secret_name = \"development-opensearch-master-user\" # If using the CloudFormation template, this is created as {environment}-opensearch-master-user. Update as appropriate.\n",
    "\n",
    "admin_role_auth = AWS4Auth(\n",
    "    credentials['AccessKeyId'],\n",
    "    credentials['SecretAccessKey'],\n",
    "    region,\n",
    "    service,\n",
    "    session_token=credentials['SessionToken']\n",
    ")\n",
    "\n",
    "# 2. Create a basic auth using the admin user/password from Secrets Manager\n",
    "client = boto3.session.Session().client(service_name='secretsmanager',region_name=region)\n",
    "get_secret_value_response = client.get_secret_value(SecretId=master_secret_name)\n",
    "\n",
    "secret_dict = json.loads(get_secret_value_response['SecretString'])\n",
    "admin_user_auth = (secret_dict['username'], secret_dict['password'])\n",
    "\n",
    "print(f\"Successfully created the authentication credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Connection using OpenSearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 9200}],\n",
    "    http_auth=admin_user_auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300,\n",
    "    retry_on_timeout=True,\n",
    "    max_retries=3,\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "# Test the connection - \n",
    "cluster_info = opensearch_client.info() \n",
    "print(f\"Successfully connected to OpenSearch cluster: {cluster_info['cluster_name']}\")\n",
    "\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", region_name=region)\n",
    "embedding_model_id = \"amazon.titan-embed-text-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to ingest documents to OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_opensearch(content, tenant_id, metadata=None):\n",
    "    path = 'surveys/_doc'\n",
    "    url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "    document = {\n",
    "        \"content\": content,\n",
    "        \"tenant_id\": tenant_id\n",
    "    }\n",
    "    if metadata:\n",
    "        document[\"metadata\"] = metadata\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = requests.post(url, auth=admin_user_auth, json=document, headers=headers, verify=False)\n",
    "    print(response.text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to read a Tenant PDF and convert it to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tenant_document(file_name, tenantid):\n",
    "    # Load the document\n",
    "    loader = PyPDFLoader(file_name)\n",
    "    doc = loader.load()\n",
    "\n",
    "    # split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10000,\n",
    "    chunk_overlap=150\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(doc)\n",
    "\n",
    "    # write each chunk into opensearch vector store\n",
    "    for chunk in chunks:\n",
    "        write_to_opensearch(chunk.page_content, tenantid)\n",
    "\n",
    "    return \"Embeddings generated successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to Invoke Anthrophic Claude LLM on Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_message(bedrock_runtime, model_id, system_prompt, messages, max_tokens):\n",
    "\n",
    "    body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": messages\n",
    "        }  \n",
    "    )  \n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "   \n",
    "    return response_body\n",
    "\n",
    "def invoke_llm_with_rag(messages):\n",
    "    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    \n",
    "    response = generate_message (bedrock_runtime, model_id, \"\", messages, 300)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to generate vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_embeddings(data):\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"inputText\": data,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Invoke model\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body,\n",
    "        modelId=embedding_model_id,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Configure the IAM Roles and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create the IAM roles required for OpenSearch to call Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject these variable values into the policy templates and generate policies using sed. \n",
    "\n",
    "%env region_name = $region\n",
    "%env account_id = $account_id\n",
    "%env embedding_model_id = $embedding_model_id\n",
    "\n",
    "!sed -e \"s/\\#embedding_model_id\\#/$embedding_model_id/\" -e \"s/\\#region_name\\#/$region_name/\" policy-templates/bedrock_model_permissions_policy.json > bedrock_model_permissions_policy.json\n",
    "!sed -e \"s/\\#account_id\\#/$account_id/\" -e \"s/\\#region_name\\#/$region_name/\" policy-templates/bedrock_trust_relationship_policy.json > bedrock_trust_relationship_policy.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opensearch-bedrock-role\n",
    "!aws iam create-role \\\n",
    "    --role-name opensearch-bedrock-role \\\n",
    "    --assume-role-policy-document file://bedrock_trust_relationship_policy.json\n",
    "\n",
    "# opensearch_permissions_policy\n",
    "!aws iam create-policy \\\n",
    "    --policy-name opensearch-bedrock-role-policy \\\n",
    "    --policy-document file://bedrock_model_permissions_policy.json\n",
    "\n",
    "!aws iam attach-role-policy \\\n",
    "    --role-name opensearch-bedrock-role \\\n",
    "    --policy-arn \"arn:aws:iam::$account_id:policy/opensearch-bedrock-role-policy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the generated policy json files.\n",
    "!rm *.json\n",
    "role_arn = f\"arn:aws:iam::{account_id}:role/opensearch-bedrock-role\"\n",
    "role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Map the ML role in OpenSearch Dashboards \n",
    "\n",
    "Fine-grained access control introduces an additional step when setting up a connector. Even if you use HTTP basic authentication for all other purposes, you need to map the ml_full_access role to your IAM role that has iam:PassRole permissions to pass opensearch-bedrock-role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '_plugins/_security/api/rolesmapping/ml_full_access'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "role_arn1 = f\"arn:aws:iam::{account_id}:role/opensearch-bedrock-role\"\n",
    "role_arn2 = f\"arn:aws:iam::{account_id}:role/opensearch-admin-role\"\n",
    "\n",
    "# Role mapping payload\n",
    "payload = {\n",
    "    \"backend_roles\": [role_arn1, role_arn2],\n",
    "    \"hosts\": [],\n",
    "    \"users\": []\n",
    "}\n",
    "\n",
    "# Send PUT request to update role mapping\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "r = requests.put(url, auth=admin_user_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "\n",
    "# Send GET request to verify role mapping\n",
    "r = requests.get(url, auth=admin_user_auth, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Configure the OpenSearch ML Connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create the remote model connector in OpenSearch\n",
    "\n",
    "This example is using the Amazon Titan Embeddings model, but you could use any embeddings model you like. This example consumes the model via the Amazon Bedrock service, but again you could use SageMaker or an external API that hosts the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '_plugins/_ml/connectors/_create'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"name\": \"Amazon Bedrock Connector: embedding\",\n",
    "  \"description\": \"The connector to bedrock Titan embedding model\",\n",
    "  \"version\": 1,\n",
    "  \"protocol\": \"aws_sigv4\",\n",
    "  \"parameters\": {\n",
    "    \"region\": region,\n",
    "    \"service_name\": \"bedrock\"\n",
    "  },\n",
    "  \"credential\": {\n",
    "    \"roleArn\": role_arn\n",
    "  },\n",
    "  \"actions\": [\n",
    "    {\n",
    "      \"action_type\": \"predict\",\n",
    "      \"method\": \"POST\",\n",
    "      \"url\": \"https://bedrock-runtime.${parameters.region}.amazonaws.com/model/\" + embedding_model_id + \"/invoke\",\n",
    "      \"headers\": {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"x-amz-content-sha256\": \"required\"\n",
    "      },\n",
    "      \"request_body\": \"{ \\\"inputText\\\": \\\"${parameters.inputText}\\\" }\",\n",
    "      \"pre_process_function\": \"connector.pre_process.bedrock.embedding\",\n",
    "      \"post_process_function\": \"connector.post_process.bedrock.embedding\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.post(url, auth=admin_role_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "connector_id = json.loads(r.text)['connector_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create the Model Group in OpenSearch and register the connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create remote model group\n",
    "path = '_plugins/_ml/model_groups/_register'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"name\": \"remote_model_group\",\n",
    "  \"description\": \"A model group for external models\"\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.post(url, auth=admin_role_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "model_group_id = json.loads(r.text)['model_group_id']\n",
    "\n",
    "# Register the remote model\n",
    "path = '_plugins/_ml/models/_register'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "    \"name\": \"Amazon Titan Embeddings\",\n",
    "    \"function_name\": \"remote\",\n",
    "    \"model_group_id\": model_group_id,\n",
    "    \"description\": \"Titan remote model\",\n",
    "    \"connector_id\": connector_id\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.post(url, auth=admin_role_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "task_id = json.loads(r.text)['task_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Check the status of the model registration task\n",
    "\n",
    "Note: if this does not show \"COMPLETED\" after running the first time, wait a couple of seconds and run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '_plugins/_ml/tasks/' + task_id\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "r = requests.get(url, auth=admin_role_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "model_id = json.loads(r.text)['model_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Test running remote inference using the model\n",
    "- Since we are testing the Titan embedding model, the inference response should contain the vector embeddings corresponding to the inputText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_id)\n",
    "path = f'_plugins/_ml/models/{model_id}/_predict'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"parameters\": {\n",
    "    \"inputText\": \"What is the meaning of life?\"\n",
    "  }\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.post(url, auth=admin_role_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "\n",
    "print(json.loads(r.text)['inference_results'][0]['output'][0]['data'][:10]) # printing only first 10 elements of the embedding vector\n",
    "print(len(json.loads(r.text)['inference_results'][0]['output'][0]['data'])) # printing the length of the embedding vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Provision the ingestion pipeline and vector store index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create an Ingestion Pipeline in OpenSearch\n",
    "\n",
    "The ingestion pipeline will run when documents are written to the index it is associated with. This will then call the specified model and write the result back to the mapped field. In this case mapping the content field from the original document to a generated embeddings field we will use for vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '_ingest/pipeline/bedrock_pipeline'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "pipeline_config = {\n",
    "    \"description\": \"Ingestion pipeline for Bedrock model\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\n",
    "                    \"content\": \"embedding\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.put(url, auth=admin_user_auth, json=pipeline_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create an index \n",
    "\n",
    "This index will contain the documents and the generated embeddings we will use for performing a neural search. The index specifies which ingestion pipeline to use as documents are written to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/surveys'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "index_config = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True,\n",
    "    \"default_pipeline\": \"bedrock_pipeline\"\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1536,\n",
    "        \"method\": {\n",
    "          \"engine\": \"lucene\",\n",
    "          \"space_type\": \"l2\",\n",
    "          \"name\": \"hnsw\",\n",
    "          \"parameters\": {}\n",
    "        },\n",
    "      },\n",
    "      \"content\": {\n",
    "        \"type\": \"text\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.put(url, auth=admin_user_auth, json=index_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate vector embeddings and insert into vector store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Insert Tenant1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_tenant_document(\n",
    "    file_name=\"../multi_tenant_survey_reports/Home_Survey_Tenant1.pdf\",\n",
    "    tenantid=\"tenant1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2: Search and validate tenant1 data and generated embeddings are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/surveys/_search'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "search_config = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"neural\": {\n",
    "                \"embedding\": {\n",
    "                  \"query_text\": \"What is the state of the roof?\",\n",
    "                  \"model_id\": model_id,\n",
    "                  \"k\": 100\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.5\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"match\": {\n",
    "                \"content\": \"What is the state of the roof?\"\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.7\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.get(url, auth=admin_user_auth, json=search_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "\n",
    "hits = json.loads(r.text)['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tenant_id'])\n",
    "    print(hit['_source']['embedding'][:10]) # Printing only the first 10 elements of the embedding\n",
    "    print(hit['_source']['content'][:100]) # Printing only the first 100 characters of the content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Insert Tenant2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_tenant_document(\n",
    "    file_name=\"../multi_tenant_survey_reports/Home_Survey_Tenant2.pdf\",\n",
    "    tenantid=\"tenant2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 - Verify that data for both tenants is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'surveys/_search'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "search_config = {\n",
    "  \"_source\": {\n",
    "    \"excludes\": [\n",
    "      \"embedding\"\n",
    "    ]\n",
    "  },\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"neural\": {\n",
    "                \"embedding\": {\n",
    "                  \"query_text\": \"What is the state of the roof ?\",\n",
    "                  \"model_id\": model_id,\n",
    "                  \"k\": 100\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.5\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"match\": {\n",
    "                \"content\": \"What is the state of the roof ?\"\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.7\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.get(url, auth=admin_user_auth, json=search_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "\n",
    "hits = json.loads(r.text)['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tenant_id'])\n",
    "    print(hit['_source']['content'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Enforce multi-tenant data isolation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Apply a filter to the query so that only documents where the tenant_id is tenant1 are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/surveys/_search'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "search_config = {\n",
    "  \"_source\": {\n",
    "    \"excludes\": [\n",
    "      \"embedding\"\n",
    "    ]\n",
    "  },\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": {\n",
    "         \"wildcard\":  { \"tenant_id\": \"tenant1\" }\n",
    "      },\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"neural\": {\n",
    "                \"embedding\": {\n",
    "                  \"query_text\": \"Property contents and state\",\n",
    "                  \"model_id\": model_id,\n",
    "                  \"k\": 100\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.5\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"match\": {\n",
    "                \"content\": \"Property contents and state\"\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.7\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "r = requests.get(url, auth=admin_user_auth, json=search_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "\n",
    "hits = json.loads(r.text)['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tenant_id'])\n",
    "    print(hit['_source']['content'][:100]) # Printing only the first 100 characters of the content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Enforce document level security by creating a role for tenant_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create role for tenant1\n",
    "path = '_plugins/_security/api/roles/tenant_1'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"cluster_permissions\": [\n",
    "    \"*\"\n",
    "  ],\n",
    "  \"index_permissions\": [{\n",
    "    \"index_patterns\": [\n",
    "      \"surveys*\"\n",
    "    ],\n",
    "    \"dls\": \"{\\\"term\\\": { \\\"tenant_id\\\": \\\"tenant1\\\"}}\",\n",
    "    \"allowed_actions\": [\n",
    "      \"read\"\n",
    "    ]\n",
    "  }]\n",
    "}\n",
    "\n",
    "r = requests.put(url, auth=admin_user_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "\n",
    "# create user for tenant1\n",
    "path = '_plugins/_security/api/internalusers/tenant_1'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"password\": \"t3n4Nt1!?\",\n",
    "}\n",
    "\n",
    "r = requests.put(url, auth=admin_user_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "\n",
    "# map user to role\n",
    "path = '_plugins/_security/api/rolesmapping/tenant_1'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "payload = {\n",
    "  \"users\" : [ \"tenant_1\" ]\n",
    "}\n",
    "\n",
    "r = requests.put(url, auth=admin_user_auth, json=payload, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Use the newly created tenant_1 user to query the index\n",
    "\n",
    "Note that even with the filter omitted, only data for tenant 1 is returned as the document level security policy filters the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/surveys/_search'\n",
    "url = 'https://' + host + ':9200/' + path \n",
    "\n",
    "search = {\n",
    "  \"_source\": {\n",
    "    \"excludes\": [\n",
    "      \"embedding\"\n",
    "    ]\n",
    "  },\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"neural\": {\n",
    "                \"embedding\": {\n",
    "                  \"query_text\": \"What is the state of the roof?\",\n",
    "                  \"model_id\": model_id,\n",
    "                  \"k\": 100\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.5\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"query\": {\n",
    "              \"match\": {\n",
    "                \"content\": \"What is the state of the roof?\"\n",
    "              }\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"source\": \"_score * 1.7\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "tenant_scoped_auth= (\"tenant_1\",\"t3n4Nt1!?\")\n",
    "\n",
    "r = requests.get(url, auth=tenant_scoped_auth, json=search_config, headers=headers, verify=False)\n",
    "print(r.status_code)\n",
    "\n",
    "hits = json.loads(r.text)['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tenant_id'])\n",
    "    print(hit['_source']['content'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Define a function to query vector embeddings from the vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_store(query, tenant_scoped_auth):\n",
    "    search_config = {\n",
    "        \"_source\": {\n",
    "            \"excludes\": [\n",
    "            \"embedding\"\n",
    "            ]\n",
    "        },\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\n",
    "                    \"neural\": {\n",
    "                        \"embedding\": {\n",
    "                        \"query_text\": query,\n",
    "                        \"model_id\": model_id,\n",
    "                        \"k\": 100\n",
    "                        }\n",
    "                    }\n",
    "                    },\n",
    "                    \"script\": {\n",
    "                    \"source\": \"_score * 1.5\"\n",
    "                    }\n",
    "                }\n",
    "                },\n",
    "                {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"content\": query\n",
    "                    }\n",
    "                    },\n",
    "                    \"script\": {\n",
    "                    \"source\": \"_score * 1.7\"\n",
    "                    }\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    r = requests.get(url, auth=tenant_scoped_auth, json=search_config, headers=headers, verify=False)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Run a user query using the vector embedding. \n",
    "Review the results from the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query data and convert it to vector embeddings to query from the vector store\n",
    "question = \"What is the condition of the roof in my survey report?\"\n",
    "tenant_scoped_auth= (\"tenant_1\",\"t3n4Nt1!?\")\n",
    "query_response = query_vector_store(question, tenant_scoped_auth)\n",
    "\n",
    "hits = json.loads(query_response)['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tenant_id'])\n",
    "    print(hit['_source']['content'][:100]) # print the first 100 characters of the document\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Augment the prompt with the context data from the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['_source']['content'])\n",
    "    return contexts\n",
    "\n",
    "contexts = get_contexts(hits)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context\n",
    "Question: {question}\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Invoke the LLM with the augmented prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(contexts, question)}]}]\n",
    "llm_response = invoke_llm_with_rag(messages)\n",
    "print(llm_response['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detach Policy from role\n",
    "\n",
    "!aws iam detach-role-policy --role-name opensearch-bedrock-role-policy --policy-arn \"arn:aws:iam::$account_id:policy/opensearch-bedrock-role-policy\"\n",
    "\n",
    "# Delete policy\n",
    "!aws iam delete-policy --policy-arn \"arn:aws:iam::$account_id:policy/opensearch-bedrock-role-policy\"\n",
    "\n",
    "# Delete role\n",
    "!aws iam delete-role --role-name opensearch-bedrock-role\n",
    "\n",
    "\n",
    "print(\"Clean up completed !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "We now successfully implemented a self-managed vector store using Amazon OpenSearch service. Also we learnt how to configure tenant isolation using the filters and document level security features to enforce tenant isolation. Overall we used the following features : \n",
    "\n",
    "- Amazon OpenSearch ML Connectors : To integrate OpenSearch with Bedrock service for LLM access. \n",
    "- Amazon OpenSearch Ingestion Pipelines : To transform the input data chunks to embeddings automatically before indexing.\n",
    "- Amazon OpenSearch filters : To achieve tenant isolation. \n",
    "- Amazon OpenSearch document level security: To achieve tenant isolation\n",
    "- Amazon OpenSearch Cluster : To index and store vector embeddings\n",
    "- Amazon Bedrock Titan Embeddings model - Generate vector embeddings. \n",
    "- Amazon Bedrock Anthrophic Claude Foundation model - To generate response back to user. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
